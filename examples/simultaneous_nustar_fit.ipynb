{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit NuSTAR FPMA and FPMB simultaneously: single thermal component, no pileup correction, no gain correction\n",
    "\n",
    "Here we demonstrate how one may perform simultaneous spectral fitting with the two NuSTAR detectors.\n",
    "\n",
    "The NuSTAR data fit here is a quiet sun brightening on 8 Jan 2021 11:57:25UTC to 11:59:23UTC, orbit ID 20612002001, grades 0-4.\n",
    "\n",
    "We supply the data from the pipeline as an ASDF file which may be downloaded from [here](https://drive.google.com/file/d/19BeSwSACum5lb0TE9BN7dyos91XP5L3O).\n",
    "\n",
    "The procedure is basically as follows:\n",
    "1. Load the data for each detector into a `fitting.DataPacket`.\n",
    "2. Construct a `fitting.BayesFitter` or some other kind of fitting object for each detector:\n",
    "    - Give each the proper data packet\n",
    "    - Give each a set of parameters, log priors, model, and log likelihood.\n",
    "      In this example we use a Poisson likelihood and single thermal model.\n",
    "      There are several bins with only ~1-5 counts so the difference between\n",
    "      Poisson statistics and Gaussian statistics is significant.\n",
    "3. Minimize each data set individually using Levenberg-Marquadt least squares (like XSPEC)\n",
    "    - This gives a good starting guess for the composite minimization\n",
    "4. Construct a `fitting.CompositeBayesFitter` which coordinates parameter sharing between the two `BayesFitter`s. During this construction, you must supply a set of parameters which are shared between the models in each `BayesFitter`.\n",
    "5. Run `emcee` on the Composite fitter.\n",
    "\n",
    "If you want to fit different energy ranges with the models, modify the log likelihoods (at any time) to adjust the fit range under consideration.\n",
    "\n",
    "**If you want to perform a \"fancy\" parameter transformation,** put it in your model function. The \"shared\" parameters get the same _values_ passed to the model functions, but the model functions themselves may scale or operate on them however necessary. For example, if you want to fit something where a parameter is twice the temperature of the \"shared\" temperature, just add the factor of 2 in the model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set this so that matrix multiplication doesn't take up too many CPU cores\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "import asdf\n",
    "import astropy.units as u\n",
    "import corner\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('nice.mplstyle')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "import yaff.fitting as fitting\n",
    "import importlib\n",
    "importlib.reload(fitting)\n",
    "from yaff import plotting as yap\n",
    "from yaff import common_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model function: we are just fitting a single thermal component here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thermal(arg_dict: dict[str, object]):\n",
    "    # Imports need to be inside the model\n",
    "    # function for pickling/multiprocessing\n",
    "    from sunkit_spex.legacy import thermal\n",
    "\n",
    "    # The dict type annotation in the function\n",
    "    # declaration is ambiguous; so, annotate the variables here\n",
    "    ph_edges: np.ndarray = arg_dict['photon_energy_edges']\n",
    "    params: dict[str, fitting.Parameter] = arg_dict['parameters']\n",
    "\n",
    "    thermal_portion = thermal.thermal_emission(\n",
    "        energy_edges=ph_edges << u.keV,\n",
    "        temperature=params['temperature'].as_quantity(),\n",
    "        emission_measure=params['emission_measure'].as_quantity()\n",
    "    ).to_value(u.ph / u.s / u.keV / u.cm**2)\n",
    "\n",
    "    return thermal_portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model parameters and their priors (aka bounds in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters with their initial guesses (all free to start)\n",
    "starting_parameters = {\n",
    "    'temperature': fitting.Parameter(10 << u.MK, frozen=False),\n",
    "    'emission_measure': fitting.Parameter(2 << (1e44 * u.cm**-3), frozen=False),\n",
    "}\n",
    "\n",
    "# The priors we give are just \"bounds\" on\n",
    "# the physical values. They could be something\n",
    "# more interesting like a truncated normal,\n",
    "# or some other probability distribution.\n",
    "log_priors = {\n",
    "    'temperature': fitting.simple_bounds(0, 100),\n",
    "    'emission_measure': fitting.simple_bounds(0, 1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in all of the data into \"packets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_packs: list[fitting.DataPacket] = list()\n",
    "\n",
    "with asdf.open('nustar_example.asdf') as af:\n",
    "    for fpm in ('FPMA', 'FPMB'):\n",
    "        this_dat = af[fpm]\n",
    "        data_packs.append(fitting.DataPacket(\n",
    "            counts=this_dat['counts'],\n",
    "            counts_error=this_dat['counts_error'],\n",
    "            background_counts=this_dat['background_counts'],\n",
    "            background_counts_error=this_dat['background_counts_error'],\n",
    "            effective_exposure=this_dat['effective_exposure'],\n",
    "            count_energy_edges=this_dat['count_energy_edges'],\n",
    "            photon_energy_edges=this_dat['photon_energy_edges'],\n",
    "            response_matrix=this_dat['response_matrix']\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this event, we need to use a Poisson likelihood (or an approximation thereof) because we have very few counts in some bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit only a small energy range\n",
    "# The data pack energy units default to keV\n",
    "mids = data_packs[0].count_energy_mids\n",
    "restrict = (2.5 <= mids) & (mids <= 5)\n",
    "log_likelihood = common_likelihoods.poisson_factory(restrict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct `BayesFitter`s for both focal plane module A (FPMA) and FPMB\n",
    "Here we assume there is no background (this is a quiet Sun brightening),\n",
    "and we also assume that the model is exactly the same between them (single thermal).\n",
    "\n",
    "If we wanted to have separate models we would have to assign one of the fitters that model.\n",
    "Not a problem, just something to be aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data output from the NuSTAR pipeline\n",
    "fitters: list[fitting.BayesFitter] = []\n",
    "for dp in data_packs:\n",
    "    # Add a fitter with the current data packet\n",
    "    fitters.append(fitting.BayesFitter(\n",
    "        data=dp,\n",
    "        model_function=thermal,\n",
    "        parameters=starting_parameters,\n",
    "        log_priors=log_priors,\n",
    "        log_likelihood=log_likelihood\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the data is loaded and parameters are set up, minimize them using Levenberg-Marquadt like XSPEC to get them close to the \"true\" best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(fitting)\n",
    "# Minimize individually with levenberg-marquadt\n",
    "fita, fitb = fitters\n",
    "\n",
    "_ = fitting.levenberg_minimize(fita)\n",
    "_ = fitting.levenberg_minimize(fitb)\n",
    "\n",
    "fita.parameters, fitb.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the current \"best fits\" to see how things are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(yap)\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "figa, figb = fig.subfigures(nrows=1, ncols=2)\n",
    "\n",
    "reta = yap.plot_data_model(fita, [fita.eval_model()], fig=figa)\n",
    "retb = yap.plot_data_model(fitb, [fitb.eval_model()], fig=figb)\n",
    "\n",
    "for dat in (reta, retb):\n",
    "    dat['data_ax'].set(xlim=(2.2, 5.2), xscale='linear', ylim=(0.1, 120))\n",
    "\n",
    "reta['data_ax'].set(title='FPMA fit (black) vs data (blue)')\n",
    "retb['data_ax'].set(title='FPMB fit (black) vs data (blue)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the composite fitter out of the two `BayesFitter`s, indicating that `temperature` is the only shared parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a composite fitter where both parameters are shared\n",
    "# between the models\n",
    "composite = fitting.CompositeBayesFitter(\n",
    "    individual_fitters=fitters,\n",
    "    shared_param_names=['temperature']\n",
    ")\n",
    "\n",
    "# Constrain the temperature, but let the emission measures vary independently.\n",
    "composite.shared_params['temperature'].frozen = False\n",
    "\n",
    "# Parameters are associated with sub-fitters, or they are shared\n",
    "composite.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We already have a good starting guess, so cut to the chase with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite.run_emcee({'nwalkers': 16}, {'nsteps': 500, 'progress': True})\n",
    "\n",
    "# Save the object if you want for later retrieval\n",
    "# It gets \"pickled\" with the `dill` library which is more versatile\n",
    "# import lzma\n",
    "# composite.save('nustar-composite.dill.xz', open_func=lzma.open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the resulting parameter chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yap.plot_parameter_chains(\n",
    "    fitter=composite,\n",
    "    names=composite.free_param_names,\n",
    "    params=composite.free_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a few samples from the model parameters, after \"burning-in\" the MCMC chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the flattened chain we need to multiply by\n",
    "# the number of walkers (stored in shape[0])\n",
    "burn = 200 * composite.emcee_sampler.chain.shape[0]\n",
    "flat = composite.emcee_sampler.flatchain.T\n",
    "tch, em_ach, em_bch = flat[:, burn:]\n",
    "\n",
    "num = 50\n",
    "rng = np.random.default_rng()\n",
    "fpma_samples = rng.choice(np.array((tch, em_ach)).T, size=num)\n",
    "fpmb_samples = rng.choice(np.array((tch, em_bch)).T, size=num)\n",
    "\n",
    "fita, fitb = fitters\n",
    "\n",
    "fpma_mods = list()\n",
    "for (t, em) in fpma_samples:\n",
    "    fita.parameters['temperature'].value = t\n",
    "    fita.parameters['emission_measure'].value = em\n",
    "    fpma_mods.append(fita.eval_model())\n",
    "\n",
    "fpmb_mods = list()\n",
    "for (t, em) in fpmb_samples:\n",
    "    fitb.parameters['temperature'].value = t\n",
    "    fitb.parameters['emission_measure'].value = em\n",
    "    fpmb_mods.append(fitb.eval_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model samples on top of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give each focal plane module a figure\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "figa, figb = fig.subfigures(nrows=1, ncols=2)\n",
    "\n",
    "reta = yap.plot_data_model(fita, fpma_mods, figa)\n",
    "reta['data_ax'].set(title='FPMA: data vs model')\n",
    "\n",
    "retb = yap.plot_data_model(fitb, fpmb_mods, figb)\n",
    "retb['data_ax'].set(title='FPMB: data vs model')\n",
    "\n",
    "for r in reta, retb:\n",
    "    r['data_ax'].set(ylim=(1e-1, 1e2), xlim=(2.2, 5.8), xscale='linear')\n",
    "\n",
    "fig.suptitle('NuSTAR simultaneous fit: Poisson likelihood')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make corner plots of the parameters we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_flatchain = composite.emcee_sampler.flatchain[burn:]\n",
    "param_names = ['T (MK)', 'FPMA EM (1e44 cm-3)', 'FPMB EM (1e44 cm-3)']\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8), layout='tight')\n",
    "corner.corner(\n",
    "    burned_flatchain,\n",
    "    bins=20,\n",
    "    labels=param_names,\n",
    "    show_titles=True,\n",
    "    fig=fig,\n",
    "    # 90% credible intervals annotated\n",
    "    quantiles=(0.05, 0.5, 0.95)\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
