{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a real flare: 2011 RHESSI M9\n",
    "### You may download the data for this flare from this [Google Drive link](https://drive.google.com/file/d/1eL5cczLQX-VPCCEQDrW6WXByTcbhYdEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import astropy.time as atime\n",
    "import numpy as np\n",
    "from sunkit_spex.extern import rhessi\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.style.use('nice.mplstyle')\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from example_support import adapt_rhessi_data, thermal_and_thick\n",
    "from yaff import fitting\n",
    "from yaff import plotting as yap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we load the data in using `sunkit_spex.extern.rhessi.RhessiLoader` and adapt it to the target format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data and set the event/background times\n",
    "\n",
    "rl = rhessi.RhessiLoader(\n",
    "    spectrum_fn='rhessi-data/trevor-flare-30-jul-2011-logspace-bkg_spec.fits',\n",
    "    srm_fn='rhessi-data/trevor-flare-30-jul-2011-logspace-bkg_srm.fits',\n",
    ")\n",
    "\n",
    "start_event_time = atime.Time('2011-07-30T02:08:20')\n",
    "end_event_time = atime.Time('2011-07-30T02:10:20')\n",
    "start_background_time = atime.Time('2011-07-30T01:54:00')\n",
    "end_background_time = atime.Time('2011-07-30T01:56:00')\n",
    "rl.update_event_times(start_event_time, end_event_time)\n",
    "rl.update_background_times(start_background_time, end_background_time)\n",
    "\n",
    "# Add on a 10% systematic error\n",
    "rl.systematic_error = 0.1\n",
    "\n",
    "# Put the \"sunkit-spex\" format into a DataPacket\n",
    "dp = adapt_rhessi_data(rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we define the log likelihood function to use and parameters\n",
    "- The `log_likelihood` enforces the \"energy fitting range\"---no fancy logic required to enforce this elsewhere\n",
    "- The parameters are explicitly declared with units and \"frozen\" state. This is verbose, but the intent is clear.\n",
    "- Finally, log priors are placed on the parameters. In this case, the prior is just a uniform prior (aka \"bounds\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The background counts are scaled\n",
    "# by effective exposure already.\n",
    "background_counts = rl['extras']['background_rate'] * rl['count_channel_binning'] * rl['effective_exposure']\n",
    "\n",
    "# Set energy bounds to restrict where we care about the likelihood\n",
    "mids = dp.count_energy_edges[:-1] + np.diff(dp.count_energy_edges)/2\n",
    "energy_bounds = (mids >= 6) & (mids <= 70)\n",
    "\n",
    "def log_likelihood(data: fitting.DataPacket, model: np.ndarray):\n",
    "    '''Basic chi2 log likelihood, which subtracts the\n",
    "       background from the data'''\n",
    "    # Some count bins might be negative, so use nan_to_num\n",
    "    return -np.nan_to_num(\n",
    "        ((data.counts - background_counts - model)**2 / data.counts_error**2)[energy_bounds]\n",
    "    ).sum()\n",
    "\n",
    "# Define the parameters with their initial guesses (all frozen to start)\n",
    "starting_parameters = {\n",
    "    'temperature': fitting.Parameter(12 << u.MK, frozen=True),\n",
    "    'emission_measure': fitting.Parameter(1 << (1e49 * u.cm**-3), frozen=True),\n",
    "    'electron_flux': fitting.Parameter(20 << (1e35 * u.electron / u.s), frozen=True),\n",
    "    'spectral_index': fitting.Parameter(3 << u.one, frozen=True),\n",
    "    'cutoff_energy': fitting.Parameter(10 << u.keV, frozen=True)\n",
    "}\n",
    "\n",
    "# The priors we give are just \"bounds\" on\n",
    "# the physical values. They could be something\n",
    "# more interesting like a truncated normal,\n",
    "# or some other probability distribution.\n",
    "log_priors = {\n",
    "    'temperature': fitting.simple_bounds(0, 100),\n",
    "    'emission_measure': fitting.simple_bounds(0, 10000),\n",
    "    'electron_flux': fitting.simple_bounds(0, 10000),\n",
    "    'spectral_index': fitting.simple_bounds(2, 20),\n",
    "    'cutoff_energy': fitting.simple_bounds(1, 90)\n",
    "}\n",
    "\n",
    "# Name the parameter groups so we can loop\n",
    "# over them later\n",
    "thermal_names = ['temperature', 'emission_measure']\n",
    "nonthermal_names = ['electron_flux', 'spectral_index', 'cutoff_energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the actual fitter object with the data, model, priors, and likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitta = fitting.BayesFitter(\n",
    "    data=dp,\n",
    "    # Model function is defined in external file\n",
    "    # It's just a normal function\n",
    "    model_function=thermal_and_thick,\n",
    "    parameters=starting_parameters,\n",
    "    log_priors=log_priors,\n",
    "    log_likelihood=log_likelihood\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before proceeding to an MCMC run, we minimize the parameters using \"normal\" minimization\n",
    "- The \"normal\" minimization uses `scipy.optimize.minimize` and is a ~20 line function which uses the already-assembled `BayesFitter.log_posterior` method.\n",
    "- The \"normal\" minimizer is left as a free function rather than a method of the `BayesFitter` class to keep the code more decoupled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitta = fitting.BayesFitter(\n",
    "    data=dp,\n",
    "    model_function=thermal_and_thick,\n",
    "    parameters=starting_parameters,\n",
    "    log_priors=log_priors,\n",
    "    log_likelihood=log_likelihood\n",
    ")\n",
    "\n",
    "print(\"minimize thermal\")\n",
    "fitta = fitting.normal_minimize(fitta)\n",
    "\n",
    "print(\"minimize nonthermal\")\n",
    "for n in thermal_names:\n",
    "    fitta.parameters[n].frozen = True\n",
    "for n in nonthermal_names:\n",
    "    fitta.parameters[n].frozen = False\n",
    "fitta = fitting.normal_minimize(fitta)\n",
    "\n",
    "print(\"minimize all\")\n",
    "for n in (nonthermal_names + thermal_names):\n",
    "    fitta.parameters[n].frozen = False\n",
    "\n",
    "fitta = fitting.normal_minimize(fitta)\n",
    "\n",
    "print('\"best-fit\" parameters are:')\n",
    "fitta.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can plot the model on top of the data to see how the \"normal\" minimization did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(yap)\n",
    "yap.plot_data_model(fitta, background_counts=background_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the parameters have been (quickly) minimized via chi2, we can perturb that solution with MCMC to get meaningful uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in (thermal_names + nonthermal_names):\n",
    "    fitta.parameters[n].frozen = False\n",
    "\n",
    "fitta.perform_fit({'nwalkers': os.cpu_count() // 2}, {'nsteps': 1000, 'progress': True})\n",
    "fitta.emplace_best_mcmc()\n",
    "fitta.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the parameter chains to determine the \"burn-in,\" i.e. where the solution has converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = fitta.emcee_sampler.flatchain.T\n",
    "param_names = list(fitta.parameters.keys())\n",
    "param_units = list(v.unit for v in fitta.parameters.values())\n",
    "\n",
    "fig, axs = plt.subplots(nrows=chain.shape[0], layout='constrained', figsize=(10, 8))\n",
    "for (param_chain, name, ax, unit) in zip(chain, param_names, axs, param_units):\n",
    "    ax.plot(param_chain, label=name)\n",
    "    ax.set(title=name, ylabel=unit)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some corner plots of the parameters and annotate with 90% posterior intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "burn = 300\n",
    "corner_chain = chain.T[burn:]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "corner.corner(\n",
    "    corner_chain,\n",
    "    fig=fig,\n",
    "    bins=20,\n",
    "    labels=param_names,\n",
    "    quantiles=(0.05, 0.5, 0.95),\n",
    "    show_titles=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, plot a few (sample) models over the data. Fit seems to have worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 400\n",
    "rng = np.random.default_rng()\n",
    "some_params = rng.choice(corner_chain, size=num_samples)\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "for pset in some_params:\n",
    "    for k, v in zip(param_names, pset):\n",
    "        fitta.parameters[k].value = v\n",
    "    count_model = fitta.eval_model()\n",
    "    ax.stairs(count_model, dp.count_energy_edges, color='black', alpha=0.05)\n",
    "\n",
    "yap.stairs_with_error(\n",
    "    bins=dp.count_energy_edges << u.keV,\n",
    "    rate=(dp.counts - background_counts) << u.ct,\n",
    "    error=np.sqrt(dp.counts_error**2 + background_counts) << u.ct,\n",
    "    ax=ax,\n",
    "    line_kw={'color': 'blue', 'lw': 3},\n",
    "    label='data with error'\n",
    ")\n",
    "\n",
    "ax.stairs(background_counts, dp.count_energy_edges, color='gray', lw=3, label='pre-flare background')\n",
    "\n",
    "ax.legend()\n",
    "ax.set(title='Data (blue) vs model samples (black)', xlabel='keV', ylabel='counts', xscale='log', yscale='log', xlim=(3.5, 120), ylim=(100, 5e5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
