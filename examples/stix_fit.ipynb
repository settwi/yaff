{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example STIX flare: 22 Apr 2022, M1 GOES class\n",
    "### Data available here: [link](https://drive.google.com/file/d/1DeIlEu3S8OgkCxWcA6iOkwKPD3xb3qIz)\n",
    "\n",
    "This example is a bit more \"manual\" for data processing than the RHESSI example.\n",
    "For instance, we need to manually slice out the counts and effective exposure.\n",
    "This is very verbose but at least the intent is clear.\n",
    "\n",
    "As the STIX Python interface becomes more developed,\n",
    "a lot of the steps done by hand here will be obviated,\n",
    "and code in the `extern` module can get dropped or replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.time as atime\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.style.use('nice.mplstyle')\n",
    "\n",
    "from yaff.extern import stix\n",
    "from yaff import fitting, plotting\n",
    "\n",
    "from example_support import thermal_and_thick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in all of the data and do some massaging to make it good to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fn = 'stix data/m1-stix-pixel.fits'\n",
    "srm_fn = 'stix data/m1-stix-srm.fits'\n",
    "\n",
    "srm = stix.load_srm(srm_fn, att_state='unattenuated')\n",
    "spectrogram = stix.load_pixel_data_to_spectrogram(data_fn)\n",
    "\n",
    "# The response matrix energy bins and data energy bins don't match:\n",
    "# clip the (150, nan) keV bin from the data\n",
    "for k in ('counts', 'counts_error'):\n",
    "    spectrogram[k] = spectrogram[k][:, :-1]\n",
    "\n",
    "spectrogram['energy_bin_edges'] = spectrogram['energy_bin_edges'][:-1]\n",
    "\n",
    "# Not only that, but the livetime includes the (0, 4) keV bin, so we also\n",
    "# need to clip that (restrict the indices from 1:-1 aka cut bins 0 and 31)\n",
    "spectrogram['livetime'] = spectrogram['livetime'][:, 1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, pick some times that we want to fit by looking at the light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a nice background time before the flare and get the counts out\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "time_bins = spectrogram['time_bin_edges']\n",
    "\n",
    "cts = spectrogram['counts']\n",
    "low_energy_cts = cts[:, :cts.shape[1]//3].sum(axis=1)\n",
    "high_energy_cts = cts[:, cts.shape[1]//3:].sum(axis=1)\n",
    "dt = (time_bins[1:] - time_bins[:-1]).to(u.s)\n",
    "\n",
    "ax.stairs(low_energy_cts / dt, spectrogram['time_bin_edges'].to_datetime(), label='lower energy')\n",
    "ax.stairs(high_energy_cts / dt, spectrogram['time_bin_edges'].to_datetime(), label='higher energy')\n",
    "ax.set(xlabel='time UTC', ylabel='count / sec', yscale='log')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a pre-flare background and a few seconds in the impulsive phase to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick some times before the flare onset for background subtraction\n",
    "bkg_start, bkg_end = atime.Time(('2022-04-20T01:07:10', '2022-04-20T01:07:30'))\n",
    "\n",
    "# For event analysis, let's look at the impulsive phase\n",
    "evt_start, evt_end = atime.Time(('2022-04-20T01:08:50', '2022-04-20T01:09:00'))\n",
    "\n",
    "# Use the time bin midpoints to restrict count ranges\n",
    "# This has a couple of advantages over using the edges:\n",
    "# 1. the midpoint array is the same shape as the counts array\n",
    "# 2. the midpoints are less ambiguous in terms of \"time ranges\"\n",
    "#    because you don't need to pick \"left of\" or \"right of\" an edge\n",
    "dt = (time_bins[1:] - time_bins[:-1]).to(u.s)\n",
    "time_mids = time_bins[:-1] + dt/2\n",
    "\n",
    "# Find indices for start and end of bkg and event\n",
    "nearest = lambda a, v: np.argmin(np.abs(a - v))\n",
    "bkg_start_idx, bkg_end_idx = nearest(time_mids, bkg_start), nearest(time_mids, bkg_end)\n",
    "evt_start_idx, evt_end_idx = nearest(time_mids, evt_start), nearest(time_mids, evt_end)\n",
    "\n",
    "# Slice out the counts, errors, and effective exposure that we want\n",
    "effective_exposure = (dt * spectrogram['livetime'].T).T\n",
    "\n",
    "# Shorthand variables for slicing\n",
    "cts = spectrogram['counts']\n",
    "err = spectrogram['counts_error']\n",
    "\n",
    "event_slice = slice(evt_start_idx, evt_end_idx)\n",
    "\n",
    "sliced_counts = cts[event_slice].sum(axis=0)\n",
    "sliced_errors = np.sqrt(np.sum(err[event_slice]**2, axis=0))\n",
    "\n",
    "# Add on a 10% systematic error to all energy bins\n",
    "systematic = 0.1\n",
    "sliced_errors = np.sqrt(sliced_errors**2 + (systematic * sliced_counts)**2)\n",
    "\n",
    "# Sum up the effective exposure across the event interval\n",
    "sliced_effective_exposure = effective_exposure[event_slice].sum(axis=0)\n",
    "\n",
    "# Scale the background counts by the effective exposure\n",
    "bkg_slice = slice(bkg_start_idx, bkg_end_idx)\n",
    "scaled_bkg_counts = (cts[bkg_slice].sum(axis=0) / dt[bkg_slice].sum()) * sliced_effective_exposure\n",
    "scaled_bkg_errors = (np.sqrt(np.sum(err[bkg_slice]**2, axis=0)) / dt[bkg_slice].sum()) * sliced_effective_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrum to see if it worked out\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.stairs(scaled_bkg_counts.value, spectrogram['energy_bin_edges'].value, label='background', color='gray')\n",
    "\n",
    "plotting.stairs_with_error(\n",
    "    bins=spectrogram['energy_bin_edges'],\n",
    "    quant=sliced_counts - scaled_bkg_counts,\n",
    "    error=np.sqrt(sliced_errors**2 + scaled_bkg_errors**2),\n",
    "    ax=ax,\n",
    "    label='count data (bkg subtracted)',\n",
    "    line_kw={'color': 'red'}\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlabel='energy keV',\n",
    "    ylabel='counts',\n",
    "    xscale='log',\n",
    "    yscale='log',\n",
    "    title='STIX counts (event) and scaled background'\n",
    ")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data looks good; let's set up the fitter, parameters, and likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's steal the parameters from the RHESSI flare--single nonthermal\n",
    "# electron population with a single thermal component.\n",
    "\n",
    "# Define the parameters with their initial guesses (all frozen to start)\n",
    "starting_parameters = {\n",
    "    'temperature': fitting.Parameter(12 << u.MK, frozen=True),\n",
    "    'emission_measure': fitting.Parameter(1 << (1e49 * u.cm**-3), frozen=True),\n",
    "    'electron_flux': fitting.Parameter(20 << (1e35 * u.electron / u.s), frozen=True),\n",
    "    'spectral_index': fitting.Parameter(3 << u.one, frozen=True),\n",
    "    'cutoff_energy': fitting.Parameter(10 << u.keV, frozen=True)\n",
    "}\n",
    "\n",
    "# The priors we give are just \"bounds\" on\n",
    "# the physical values. They could be something\n",
    "# more interesting like a truncated normal,\n",
    "# or some other probability distribution.\n",
    "log_priors = {\n",
    "    'temperature': fitting.simple_bounds(0, 100),\n",
    "    'emission_measure': fitting.simple_bounds(0, 10000),\n",
    "    'electron_flux': fitting.simple_bounds(0, 10000),\n",
    "    'spectral_index': fitting.simple_bounds(2, 20),\n",
    "    'cutoff_energy': fitting.simple_bounds(1, 90)\n",
    "}\n",
    "\n",
    "# Name the parameter groups so we can loop\n",
    "# over them later\n",
    "thermal_names = ['temperature', 'emission_measure']\n",
    "nonthermal_names = ['electron_flux', 'spectral_index', 'cutoff_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time around, let's be clever when defining the likelihood function\n",
    "# so that an energy range can be dynamically swapped for fitting\n",
    "def likelihood_factory(energy_bounds: np.ndarray) -> Callable[[fitting.DataPacket, np.ndarray], float]:\n",
    "    e_start, e_end = energy_bounds\n",
    "    def log_likelihood(data: fitting.DataPacket, model: np.ndarray) -> float:\n",
    "        '''Basic chi2 log likelihood, which subtracts the\n",
    "        background from the data'''\n",
    "        restrict = (e_start <= data.count_energy_mids) & (data.count_energy_mids <= e_end)\n",
    "        # Some count bins might be negative, so use nan_to_num\n",
    "        return -np.nan_to_num(\n",
    "            ((data.counts - data.background_counts - model)**2 / (data.counts_error**2 + data.background_counts_error**2))[restrict]\n",
    "        ).sum()\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure is as follows for fitting\n",
    "1. Fit the thermal parameters from 5 to 30 keV\n",
    "2. Fit the nonthermal parameters from 20 to 100 keV\n",
    "3. Fit all parameters simultaneously from 5 to 100 keV\n",
    "4. Run MCMC on the \"best\" parameters to get uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_packet = fitting.DataPacket(\n",
    "    counts=sliced_counts,\n",
    "    counts_error=sliced_errors,\n",
    "    background_counts=scaled_bkg_counts,\n",
    "    background_counts_error=scaled_bkg_errors,\n",
    "    effective_exposure=sliced_effective_exposure,\n",
    "    count_energy_edges=spectrogram['energy_bin_edges'],\n",
    "    photon_energy_edges=srm['photon_energy_edges'],\n",
    "    # We need to take the transpose here again\n",
    "    # so that we can do (SRM) @ (photons),\n",
    "    # rather than (photons) @ (srm)\n",
    "    response_matrix=(srm['area'] * srm['srm']).T\n",
    ")\n",
    "\n",
    "log_likelihood = likelihood_factory([5, 30])\n",
    "fitter = fitting.BayesFitter(\n",
    "    data=data_packet,\n",
    "    model_function=thermal_and_thick,\n",
    "    parameters=starting_parameters,\n",
    "    log_priors=log_priors,\n",
    "    log_likelihood=log_likelihood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the nonthermal parameters using chi2 minimization\n",
    "for k in thermal_names:\n",
    "    fitter.parameters[k].frozen = False\n",
    "\n",
    "print('Fit thermal params')\n",
    "fitter = fitting.normal_minimize(fitter)\n",
    "\n",
    "# Now fit the nonthermal stuff, changing the fit range\n",
    "for k in thermal_names:\n",
    "    fitter.parameters[k].frozen = True\n",
    "for k in nonthermal_names:\n",
    "    fitter.parameters[k].frozen = False\n",
    "\n",
    "print('Fit nonthermal params')\n",
    "log_likelihood = likelihood_factory([20, 100])\n",
    "fitter.log_likelihood = log_likelihood\n",
    "fitter = fitting.normal_minimize(fitter)\n",
    "\n",
    "# Finally, fit all the parameters\n",
    "for k in fitter.parameters.keys():\n",
    "    fitter.parameters[k].frozen = False\n",
    "\n",
    "print('Fit all params')\n",
    "log_likelihood = likelihood_factory([5, 100])\n",
    "fitter.log_likelihood = log_likelihood\n",
    "fitter = fitting.normal_minimize(fitter)\n",
    "\n",
    "fitter.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the current fit to see how we're doing\n",
    "plotting.plot_data_model(fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can run MCMC on the parameters and see how the fits worked.\n",
    "fitter.perform_fit({}, {'nsteps': 1000, 'progress': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the \"best\" parameters after this MCMC run\n",
    "fitter.emplace_best_mcmc()\n",
    "fitter.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 10))\n",
    "plotting.plot_parameter_chains(fitter, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 100 * fitter.emcee_sampler.chain.shape[0]\n",
    "fig = plt.figure(figsize=(16, 16), layout='tight')\n",
    "_ = plotting.corner_plot(fitter, burnin=burnin, fig=fig)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(plotting)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plot_ret = plotting.plot_data_model(fitter, 100, fig=fig)\n",
    "\n",
    "plot_ret['data_ax'].set(ylim=(1e1, 1e5), xlim=(3, 100))\n",
    "plot_ret['error_ax'].set(ylim=(-2, 2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
