{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5606f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import astropy.time as atime\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import astropy.visualization as vis\n",
    "\n",
    "from yaff.extern import solexs\n",
    "from yaff import plotting as yap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "import os\n",
    "plt.style.use('nice.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506f86f",
   "metadata": {},
   "source": [
    "## Fetch SoLEXS data from their [data server](https://pradan.issdc.gov.in/al1/protected/payload.xhtml)\n",
    "SoLEXS data is served as daily `.zip` files which are further processed using `solexs-tools`.\n",
    "\n",
    "Here we're looking at data from 2025 August 08.\n",
    "\n",
    "We follow the procedures outlined in the [user manual](https://pradan.issdc.gov.in/al1/protected/downloadFile/solexs/SoLEXS-UserManual.pdf)\n",
    "to select and prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c957d",
   "metadata": {},
   "source": [
    "## Read in a light curve file for SDD2 and pick event/background intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ca7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"AL1_SLX_L1_20250808_v1.0/SDD2\"\n",
    "lc_file = \"AL1_SOLEXS_20250808_SDD2_L1.lc.gz\"\n",
    "with fits.open(f\"{base}/{lc_file}\") as lcf:\n",
    "    lc_dat = lcf[1]\n",
    "    dt = lc_dat.header['TIMEDEL'] << u.Unit(lc_dat.header['TIMEUNIT'])\n",
    "    start_time = atime.Time(lc_dat.header['TSTART'], format='unix')\n",
    "    lightcurve_all_counts = lc_dat.data['COUNTS'].astype(float)\n",
    "    lightcurve_time_bins = start_time + np.arange(lightcurve_all_counts.size + 1) * dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce2092",
   "metadata": {},
   "source": [
    "Let's use the interval from 03:50 to 03:52, near the peak of an M class flare, for the event.\n",
    "\n",
    "For background, let's use 03:32 to 03:33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7513ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.stairs(lightcurve_all_counts, lightcurve_time_bins.datetime, color='black')\n",
    "\n",
    "analysis_interval = atime.Time(['2025-08-08T03:50:00Z', '2025-08-08T03:52:00Z'])\n",
    "\n",
    "ax.axvspan(\n",
    "    *analysis_interval.datetime,\n",
    "    color='green',\n",
    "    alpha=0.4,\n",
    "    label='analysis interval'\n",
    ")\n",
    "\n",
    "# Plot a segment around the interval of interest\n",
    "plot_buffer = 30 << u.min\n",
    "ax.set(\n",
    "    yscale='log',\n",
    "    ylabel='counts',\n",
    "    title='solexs all counts for day',\n",
    "    xlim=(\n",
    "        (analysis_interval[0] - plot_buffer).datetime,\n",
    "        (analysis_interval[1] + plot_buffer).datetime,\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de6221",
   "metadata": {},
   "source": [
    "## Generate the SoLEXS spectrum and response files\n",
    "The [`solexs-tools`](https://pradan.issdc.gov.in/al1/protected/downloadFile/solexs/solexs_tools-1.1.tar.gz) package may be downloaded from their data distribution websitie and installed into a Python environment.\n",
    "The setup is outlined in the [user manual](https://pradan.issdc.gov.in/al1/protected/downloadFile/solexs/SoLEXS-UserManual.pdf).\n",
    "Install the tools before continuing.\n",
    "\n",
    "Using the time intervals we selected before,\n",
    "you can run the following `bash` snippets to slice the SoLEXS data into spectrum files.\n",
    "During the slicing,\n",
    "    the effective area (ARF) and energy redistribution (RMF) file paths will be printed\n",
    "\n",
    "### Step 1: flare data\n",
    "```bash\n",
    "t1=\"2025-08-08T03:50:00\"\n",
    "t1=$(echo $(solexs-utc2time \"$t1\") | cut -d' ' -f3)\n",
    "\n",
    "t2=\"2025-08-08T03:52:00\"\n",
    "t2=$(echo $(solexs-utc2time \"$t2\") | cut -d' ' -f3)\n",
    "\n",
    "# Generate a spectrum from the L1 data files\n",
    "spec_fn=\"AL1_SLX_L1_20250808_v1.0/SDD2/AL1_SOLEXS_20250808_SDD2_L1.pi.gz\"\n",
    "gti_fn=\"AL1_SLX_L1_20250808_v1.0/SDD2/AL1_SOLEXS_20250808_SDD2_L1.gti.gz\"\n",
    "\n",
    "solexs-genspec -i \"$spec_fn\" \\\n",
    "    -tstart \"$t1\" -tstop \"$t2\"\\\n",
    "    -gti \"$gti_fn\"\n",
    "```\n",
    "\n",
    "### Step 2: background data\n",
    "```bash\n",
    "t1=\"2025-08-08T02:32:00\"\n",
    "t1=$(echo $(solexs-utc2time \"$t1\") | cut -d' ' -f3)\n",
    "\n",
    "t2=\"2025-08-08T03:33:00\"\n",
    "t2=$(echo $(solexs-utc2time \"$t2\") | cut -d' ' -f3)\n",
    "\n",
    "# Generate a spectrum from the L1 data files\n",
    "spec_fn=\"AL1_SLX_L1_20250808_v1.0/SDD2/AL1_SOLEXS_20250808_SDD2_L1.pi.gz\"\n",
    "gti_fn=\"AL1_SLX_L1_20250808_v1.0/SDD2/AL1_SOLEXS_20250808_SDD2_L1.gti.gz\"\n",
    "\n",
    "solexs-genspec -i \"$spec_fn\" \\\n",
    "    -tstart \"$t1\" -tstop \"$t2\"\\\n",
    "    -gti \"$gti_fn\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8406abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fn = 'AL1_SOLEXS_20250808_SDD2_L1_225000_225200.pi'\n",
    "with fits.open(data_fn) as dat:\n",
    "    cts = np.array(dat[1].data['COUNTS'], dtype=int) << u.ct\n",
    "\n",
    "    # Assume Poisson error, then add on systematics\n",
    "    sys_uncert = 0.04\n",
    "    err = np.sqrt(cts.to_value(u.ct))\n",
    "    err = np.sqrt(err**2 + (sys_uncert * cts.to_value(u.ct))**2) << u.ct\n",
    "\n",
    "bkg_fn = 'AL1_SOLEXS_20250808_SDD2_L1_213200_223300.pi'\n",
    "with fits.open(bkg_fn) as dat:\n",
    "    bkg_cts = np.array(dat[1].data['COUNTS'], dtype=int) << u.ct\n",
    "\n",
    "    # Assume Poisson error, then add on systematics\n",
    "    sys_uncert = 0.04\n",
    "    bkg_err = np.sqrt(cts.to_value(u.ct))\n",
    "    bkg_err = np.sqrt(bkg_err**2 + (sys_uncert * cts.to_value(u.ct))**2) << u.ct\n",
    "\n",
    "data_exposure = 5 << u.min\n",
    "bkg_exposure = 1 << u.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fde0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, load in the response data, using the paths output by the SoLEXS tools\n",
    "\n",
    "arf_fn = 'solexs_tools-1.1/CALDB/arf/solexs_arf_SDD2_v1.arf'\n",
    "rmf_fn = 'solexs_tools-1.1/CALDB/response/rmf/solexs_gaussian_SDD2_v1.rmf'\n",
    "\n",
    "# Put the arf and rmf data into one dict,\n",
    "# but keep the information separated by keys\n",
    "response_data = (\n",
    "    solexs.read_arf(arf_fn) |\n",
    "    solexs.read_rmf(rmf_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e375a",
   "metadata": {},
   "source": [
    "## Now that the data and response matrices have been loaded, let's define our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaff import common_models, common_likelihoods\n",
    "from yaff import fitting\n",
    "import importlib\n",
    "_ = importlib.reload(common_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunkit_spex.legacy import thermal\n",
    "import importlib\n",
    "importlib.reload(thermal)\n",
    "import copy\n",
    "\n",
    "default_abun_type = 'sun_coronal_ext'\n",
    "atomic_numbers = {\n",
    "    'mg': 12, 'al': 13,\n",
    "    'si': 14, 's': 16,\n",
    "    'ar': 18, 'ca': 20,\n",
    "    'fe': 26\n",
    "}\n",
    "# atomic_numbers = {v: k for (k, v) in atomic_numbers.items()}\n",
    "\n",
    "def thermal_with_relative_abundances(args: dict[str, object]):\n",
    "    energies: np.ndarray = args['photon_energy_edges']\n",
    "    params: dict[str, fitting.Parameter] = args['parameters']\n",
    "\n",
    "    # For every atomic number given,\n",
    "    # scale the default abundances by the coronal values.\n",
    "    rel_abuns = list()\n",
    "    for (k, v) in params.items():\n",
    "        if k not in atomic_numbers:\n",
    "            continue\n",
    "        rel_abuns.append((atomic_numbers[k], v.value))\n",
    "\n",
    "    return thermal.thermal_emission(\n",
    "        energies << u.keV,\n",
    "        temperature=params['temperature'].as_quantity(),\n",
    "        emission_measure=params['emission_measure'].as_quantity(),\n",
    "        relative_abundances=rel_abuns\n",
    "    ).to_value(u.ph / u.cm**2 / u.keV / u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out any photon bins < 1.5 keV\n",
    "# (thermal emission function doesn't like it)\n",
    "ph_bins = response_data['photon_energy_bins']\n",
    "mids = ph_bins[:-1] + np.diff(ph_bins) / 2\n",
    "\n",
    "limit = 2.5 << u.keV\n",
    "keep = (mids > limit)\n",
    "keep_edges = (ph_bins >= limit)\n",
    "\n",
    "dp = fitting.DataPacket(\n",
    "    counts=cts << u.ct,\n",
    "    counts_error=err << u.ct,\n",
    "    background_counts=0 * cts,\n",
    "    background_counts_error=0 * cts,\n",
    "    effective_exposure=data_exposure,\n",
    "    count_energy_edges=response_data['count_energy_bins'],\n",
    "    photon_energy_edges=response_data['photon_energy_bins'][keep_edges],\n",
    "    response_matrix=(response_data['effective_area'][keep] * response_data['redistribution_matrix'][:, keep])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'temperature': fitting.Parameter(20 << u.MK, frozen=False),\n",
    "    'emission_measure': fitting.Parameter(0.5 << (1e49 * u.cm**-3), frozen=False),\n",
    "}\n",
    "\n",
    "log_priors = {\n",
    "    'temperature': fitting.simple_bounds(4, 30),\n",
    "    'emission_measure': fitting.simple_bounds(1e-3, 1e3)\n",
    "}\n",
    "\n",
    "# There are a lot of elements we can vary, so add them with loops separately\n",
    "# elemental_params = ['mg', 'si', 's', 'ar', 'ca', 'fe']\n",
    "elemental_params = ['fe', 'ca', 'ar', 'si', 's']\n",
    "for n in elemental_params:\n",
    "    # For the first round, fix the abundances and just work on fitting the continuum.\n",
    "    params[n] = fitting.Parameter(1. << u.one, frozen=False)\n",
    "    log_priors[n] = fitting.simple_bounds(0.1, 3.0)\n",
    "\n",
    "lowe, highe = 3, 12\n",
    "mids = dp.count_energy_mids\n",
    "likelihood = common_likelihoods.chi_squared_factory(\n",
    "    restriction=(fit_restriction := (lowe < mids) & (mids < highe))\n",
    ")\n",
    "\n",
    "fr = fitting.BayesFitterWithGain(\n",
    "    data=dp,\n",
    "    model_function=thermal_with_relative_abundances,\n",
    "    parameters=params,\n",
    "    log_priors=log_priors,\n",
    "    log_likelihood=likelihood,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.parameters['gain_slope'].frozen = False\n",
    "fr.parameters['gain_offset'].frozen = False\n",
    "fr.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = fitting.levenberg_minimize(\n",
    "    fr,\n",
    "    restriction=fit_restriction,\n",
    "    jac='3-point',\n",
    "    ftol=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the gain params so they do not change later on\n",
    "fr.parameters['gain_offset'].frozen = True\n",
    "fr.parameters['gain_slope'].frozen = True\n",
    "fr.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80750d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ret = yap.plot_data_model(fr, fig=fig)\n",
    "ret['data_ax'].axvspan(lowe, highe, color='red', alpha=0.1, zorder=-1)\n",
    "\n",
    "mod = fr.eval_model()\n",
    "ret['data_ax'].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.run_emcee(\n",
    "    emcee_constructor_kw={'nwalkers': 20},\n",
    "    emcee_run_kw={'nsteps': 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fr.generate_model_samples(100)\n",
    "yap.plot_data_model(fr, samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "yap.plot_parameter_chains(\n",
    "    fr,\n",
    "    fr.free_param_names,\n",
    "    list(fr.free_parameters.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd9b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yaff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
